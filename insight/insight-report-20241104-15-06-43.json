{"amount_correct": 16, "percentage_score": 32, "report_time": "2024-11-04 20:06:43", "checks": [{"description": "Ensure that the README.md file exists inside of the root of the GitHub repository", "check": "ConfirmFileExists", "status": true, "path": "../README.md"}, {"description": "Delete the phrase 'Add Your Name Here' and add your own name as an Honor Code pledge in README.md", "check": "MatchFileFragment", "options": {"fragment": "Add Your Name Here", "count": 0, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 2 fragment(s) in the README.md or the output while expecting exactly 0"}, {"description": "Retype the every word in the Honor Code pledge in README.md", "check": "MatchFileFragment", "options": {"fragment": "I adhered to the Allegheny College Honor Code while completing this executable examination.", "count": 3, "exact": true}, "status": true, "path": "../README.md"}, {"description": "Indicate that you have completed all of the tasks in the README.md", "check": "MatchFileFragment", "options": {"fragment": "- [X]", "count": 10, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 0 fragment(s) in the README.md or the output while expecting exactly 10"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for README.md", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 5 fragment(s) in the README.md or the output while expecting exactly 0"}, {"description": "Ensure that question_one.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": true, "path": "questions/question_one.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_one.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "questions/question_one.py", "diagnostic": "Found 8 fragment(s) in the question_one.py or the output while expecting exactly 0"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_one.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 10, "exact": true}, "status": false, "path": "questions/question_one.py", "diagnostic": "Found 8 comment(s) in the question_one.py or the output"}, {"description": "Create a sufficient number of single-line comments in question_one.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": true, "path": "questions/question_one.py"}, {"description": "Ensure that test_question_one.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_one.py"}, {"description": "Ensure that question_two.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": true, "path": "questions/question_two.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_two.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "questions/question_two.py", "diagnostic": "Found 6 fragment(s) in the question_two.py or the output while expecting exactly 0"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_two.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 9, "exact": true}, "status": false, "path": "questions/question_two.py", "diagnostic": "Found 5 comment(s) in the question_two.py or the output"}, {"description": "Create a sufficient number of single-line comments in question_two.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": true, "path": "questions/question_two.py"}, {"description": "Ensure that test_question_two.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_two.py"}, {"description": "Ensure that question_three.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": true, "path": "questions/question_three.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_three.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "questions/question_three.py", "diagnostic": "Found 9 fragment(s) in the question_three.py or the output while expecting exactly 0"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_three.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 5, "exact": true}, "status": false, "path": "questions/question_three.py", "diagnostic": "Found 2 comment(s) in the question_three.py or the output"}, {"description": "Create a sufficient number of single-line comments in question_three.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": true, "path": "questions/question_three.py"}, {"description": "Ensure that test_question_three.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_three.py"}, {"description": "Run checks for Question 1 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_a\" --debug --no-fancy --report status --report debug", "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_b\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f2491d07170>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_c\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fc63c5eb170>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_d\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fdc54d52e10>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_a\" --debug --no-fancy --report status --report debug", "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_b\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7faa82dad760>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_c\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f4fdefbb470>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_d\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f623f9eb1d0>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_a\" --debug --no-fancy --report status --report debug", "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_b\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fcd9e1b06e0>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_c\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fd792163110>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_d\" --no-fancy --report status --report setup --report debug", "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fbc92c75760>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Ensure that Question 1 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_one.py", "status": false, "diagnostic": "questions/question_one.py:59:5: D103 Missing docstring in public function\n        |\n     59 | def encrypt_caesar_cipher(plaintext, shift=3):\n        |     ^^^^^^^^^^^^^^^^^^^^^ D103\n     60 |     result = \"\"\n     61 |     return result\n        |\n     \n     questions/question_one.py:64:5: D103 Missing docstring in public function\n        |\n     64 | def decrypt_caesar_cipher(ciphertext, shift=3):\n        |     ^^^^^^^^^^^^^^^^^^^^^ D103\n     65 |     result = \"\"\n     66 |     return result\n        |\n     \n     Found 2 errors."}, {"description": "Ensure that Question 1 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_one.py --check", "status": true}, {"description": "Ensure that Question 1 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_one.py", "status": false, "diagnostic": "questions/question_one.py:129: error: Need type annotation for \"encrypted\" (hint: \"encrypted: list[<type>] = ...\")  [var-annotated]\n     questions/question_one.py:135: error: Need type annotation for \"decrypted\" (hint: \"decrypted: list[<type>] = ...\")  [var-annotated]\n     Found 2 errors in 1 file (checked 1 source file)"}, {"description": "Ensure that Question 1 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_one.py --count", "fragment": 9, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 1 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_one.py --count", "fragment": 9, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 1 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_one.py --count", "fragment": 0, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_two.py", "status": false, "diagnostic": "questions/question_two.py:9:20: F401 [*] `typing.Callable` imported but unused\n        |\n      8 | import math\n      9 | from typing import Callable, List\n        |                    ^^^^^^^^ F401\n     10 | \n     11 | # Introduction: Read This First! {{{\n        |\n        = help: Remove unused import\n     \n     questions/question_two.py:9:30: F401 [*] `typing.List` imported but unused\n        |\n      8 | import math\n      9 | from typing import Callable, List\n        |                              ^^^^ F401\n     10 | \n     11 | # Introduction: Read This First! {{{\n        |\n        = help: Remove unused import\n     \n     questions/question_two.py:61:5: D103 Missing docstring in public function\n        |\n     61 | def encrypt_atbash_cipher(plaintext):\n        |     ^^^^^^^^^^^^^^^^^^^^^ D103\n     62 |     result = \"\"\n     63 |     return result\n        |\n     \n     questions/question_two.py:66:5: D103 Missing docstring in public function\n        |\n     66 | def decrypt_atbash_cipher(ciphertext):\n        |     ^^^^^^^^^^^^^^^^^^^^^ D103\n     67 |     result = \"\"\n     68 |     return result\n        |\n     \n     questions/question_two.py:113:5: D103 Missing docstring in public function\n         |\n     113 | def encrypt_transposition_cipher(key, message):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     114 |     ciphertext = [\"\"] * key\n     115 |     # loop through each column in ciphertext:\n         |\n     \n     questions/question_two.py:129:5: D103 Missing docstring in public function\n         |\n     129 | def decrypt_transposition_cipher(key, message):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     130 |     numOfColumns = int(math.ceil(len(message) / float(key)))\n     131 |     numOfRows = key\n         |\n     \n     Found 6 errors.\n     [*] 2 fixable with the `--fix` option."}, {"description": "Ensure that Question 2 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_two.py --check", "status": true}, {"description": "Ensure that Question 2 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_two.py", "status": true}, {"description": "Ensure that Question 2 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_two.py --count", "fragment": 8, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_two.py --count", "fragment": 8, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_two.py --count", "fragment": 0, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_three.py", "status": false, "diagnostic": "questions/question_three.py:91:5: D103 Missing docstring in public function\n        |\n     91 | def count_words_cryptanalysis(text):\n        |     ^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     92 |     cryptanalysis_dictionary = {}\n     93 |     return cryptanalysis_dictionary\n        |\n     \n     questions/question_three.py:125:5: D103 Missing docstring in public function\n         |\n     125 | def count_spaces_and_newlines_cryptanalysis(text):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     126 |     count_dict = {\"spaces\": -1, \"newlines\": -1}\n     127 |     return count_dict\n         |\n     \n     questions/question_three.py:162:5: D103 Missing docstring in public function\n         |\n     162 | def count_while_loops_malware_analysis(source_code):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     163 |     while_count = 0\n     164 |     return while_count\n         |\n     \n     Found 3 errors."}, {"description": "Ensure that Question 3 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_three.py --check", "status": true}, {"description": "Ensure that Question 3 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_three.py", "status": true}, {"description": "Ensure that Question 3 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_three.py --count", "fragment": 4, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_three.py --count", "fragment": 4, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_three.py --count", "fragment": 0, "count": 1, "exact": true}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}]}